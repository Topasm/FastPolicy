{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting robosuite==1.4\n",
      "  Downloading robosuite-1.4.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/ahrilab/anaconda3/envs/lerobot/lib/python3.10/site-packages (from robosuite==1.4) (2.2.5)\n",
      "Requirement already satisfied: numba>=0.49.1 in /home/ahrilab/anaconda3/envs/lerobot/lib/python3.10/site-packages (from robosuite==1.4) (0.61.2)\n",
      "Requirement already satisfied: scipy>=1.2.3 in /home/ahrilab/anaconda3/envs/lerobot/lib/python3.10/site-packages (from robosuite==1.4) (1.15.2)\n",
      "Requirement already satisfied: mujoco>=2.3.0 in /home/ahrilab/anaconda3/envs/lerobot/lib/python3.10/site-packages (from robosuite==1.4) (2.3.7)\n",
      "Requirement already satisfied: Pillow in /home/ahrilab/anaconda3/envs/lerobot/lib/python3.10/site-packages (from robosuite==1.4) (11.2.1)\n",
      "Requirement already satisfied: opencv-python in /home/ahrilab/anaconda3/envs/lerobot/lib/python3.10/site-packages (from robosuite==1.4) (4.11.0.86)\n",
      "Requirement already satisfied: absl-py in /home/ahrilab/anaconda3/envs/lerobot/lib/python3.10/site-packages (from mujoco>=2.3.0->robosuite==1.4) (2.2.2)\n",
      "Requirement already satisfied: glfw in /home/ahrilab/anaconda3/envs/lerobot/lib/python3.10/site-packages (from mujoco>=2.3.0->robosuite==1.4) (2.9.0)\n",
      "Requirement already satisfied: pyopengl in /home/ahrilab/anaconda3/envs/lerobot/lib/python3.10/site-packages (from mujoco>=2.3.0->robosuite==1.4) (3.1.9)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /home/ahrilab/anaconda3/envs/lerobot/lib/python3.10/site-packages (from numba>=0.49.1->robosuite==1.4) (0.44.0)\n",
      "Downloading robosuite-1.4.0-py3-none-any.whl (193.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.5/193.5 MB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: robosuite\n",
      "Successfully installed robosuite-1.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --quiet mediapy\n",
    "!pip install robosuite==1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libero.libero import benchmark\n",
    "from libero.libero.envs import OffScreenRenderEnv\n",
    "from libero.libero import get_libero_path\n",
    "import os \n",
    "import mediapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def libero_frames(task_suite_name, task_id, resize):\n",
    "\n",
    "    benchmark_dict = benchmark.get_benchmark_dict()\n",
    "    task_suite = benchmark_dict[task_suite_name]()\n",
    "\n",
    "    # retrieve a specific task\n",
    "    task = task_suite.get_task(task_id)\n",
    "    task_name = task.name\n",
    "    task_description = task.language\n",
    "    task_bddl_file = os.path.join(get_libero_path(\"bddl_files\"), task.problem_folder, task.bddl_file)\n",
    "    print(f\"[info] retrieving task {task_id} from suite {task_suite_name}, the \" + \\\n",
    "        f\"language instruction is {task_description}, and the bddl file is {task_bddl_file}\")\n",
    "\n",
    "    # step over the environment\n",
    "    env_args = {\n",
    "        \"bddl_file_name\": task_bddl_file,\n",
    "        \"camera_heights\": resize,\n",
    "        \"camera_widths\": resize\n",
    "    }\n",
    "    env = OffScreenRenderEnv(**env_args)\n",
    "    env.seed(0)\n",
    "    env.reset()\n",
    "    init_states = task_suite.get_task_init_states(task_id) # for benchmarking purpose, we fix the a set of initial states\n",
    "    env.set_init_state(init_states[0])\n",
    "\n",
    "    dummy_action = [0.] * 7\n",
    "    replay_images = []\n",
    "\n",
    "    if task_suite_name == \"libero_spatial\":\n",
    "        max_steps = 220  # longest training demo has 193 steps\n",
    "    elif task_suite_name == \"libero_object\":\n",
    "        max_steps = 280  # longest training demo has 254 steps\n",
    "    elif task_suite_name == \"libero_goal\":\n",
    "        max_steps = 300  # longest training demo has 270 steps\n",
    "    elif task_suite_name == \"libero_10\":\n",
    "        max_steps = 520  # longest training demo has 505 steps\n",
    "    elif task_suite_name == \"libero_90\":\n",
    "        max_steps = 400  # longest training demo has 373 steps\n",
    "\n",
    "    for step in range(max_steps):\n",
    "        obs, reward, done, info = env.step(dummy_action)\n",
    "        img = obs[\"agentview_image\"]\n",
    "        img = img[::-1, ::-1] \n",
    "        replay_images.append(img)\n",
    "    env.close()\n",
    "    \n",
    "    return replay_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] using task orders [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "[info] retrieving task 0 from suite libero_10, the language instruction is put both the alphabet soup and the tomato sauce in the basket, and the bddl file is /home/ahrilab/Desktop/LIBERO/libero/libero/./bddl_files/libero_10/LIVING_ROOM_SCENE2_put_both_the_alphabet_soup_and_the_tomato_sauce_in_the_basket.bddl\n"
     ]
    },
    {
     "ename": "UnpicklingError",
     "evalue": "Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL numpy.core.multiarray._reconstruct was not an allowed global by default. Please use `torch.serialization.add_safe_globals([_reconstruct])` or the `torch.serialization.safe_globals([_reconstruct])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m task_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      4\u001b[0m resize \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m512\u001b[39m\n\u001b[0;32m----> 7\u001b[0m replay_images \u001b[38;5;241m=\u001b[39m \u001b[43mlibero_frames\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask_suite_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresize\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[29], line 23\u001b[0m, in \u001b[0;36mlibero_frames\u001b[0;34m(task_suite_name, task_id, resize)\u001b[0m\n\u001b[1;32m     21\u001b[0m env\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     22\u001b[0m env\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m---> 23\u001b[0m init_states \u001b[38;5;241m=\u001b[39m \u001b[43mtask_suite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_task_init_states\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask_id\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# for benchmarking purpose, we fix the a set of initial states\u001b[39;00m\n\u001b[1;32m     24\u001b[0m env\u001b[38;5;241m.\u001b[39mset_init_state(init_states[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     26\u001b[0m dummy_action \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0.\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m7\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/LIBERO/libero/libero/benchmark/__init__.py:164\u001b[0m, in \u001b[0;36mBenchmark.get_task_init_states\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_task_init_states\u001b[39m(\u001b[38;5;28mself\u001b[39m, i):\n\u001b[1;32m    159\u001b[0m     init_states_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m    160\u001b[0m         get_libero_path(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit_states\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtasks[i]\u001b[38;5;241m.\u001b[39mproblem_folder,\n\u001b[1;32m    162\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtasks[i]\u001b[38;5;241m.\u001b[39minit_states_file,\n\u001b[1;32m    163\u001b[0m     )\n\u001b[0;32m--> 164\u001b[0m     init_states \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43minit_states_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m init_states\n",
      "File \u001b[0;32m~/anaconda3/envs/lerobot/lib/python3.10/site-packages/torch/serialization.py:1470\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1462\u001b[0m                 \u001b[38;5;28;01mreturn\u001b[39;00m _load(\n\u001b[1;32m   1463\u001b[0m                     opened_zipfile,\n\u001b[1;32m   1464\u001b[0m                     map_location,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1467\u001b[0m                     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args,\n\u001b[1;32m   1468\u001b[0m                 )\n\u001b[1;32m   1469\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1470\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1471\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _load(\n\u001b[1;32m   1472\u001b[0m             opened_zipfile,\n\u001b[1;32m   1473\u001b[0m             map_location,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1476\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args,\n\u001b[1;32m   1477\u001b[0m         )\n\u001b[1;32m   1478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n",
      "\u001b[0;31mUnpicklingError\u001b[0m: Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL numpy.core.multiarray._reconstruct was not an allowed global by default. Please use `torch.serialization.add_safe_globals([_reconstruct])` or the `torch.serialization.safe_globals([_reconstruct])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html."
     ]
    }
   ],
   "source": [
    "# [\"libero_spatial\", \"libero_object\", \"libero_goal\", \"libero_10\"]\n",
    "task_suite_name = \"libero_10\" # can also choose libero_spatial, libero_object, etc.\n",
    "task_id = 0\n",
    "resize = 512\n",
    "\n",
    "\n",
    "replay_images = libero_frames(task_suite_name, task_id, resize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'replay_images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# images = [img for img in replay_images]\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# mediapy.show_video(replay_images, fps=5)\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m mediapy\u001b[38;5;241m.\u001b[39mshow_video(\u001b[43mreplay_images\u001b[49m, fps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, codec\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgif\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'replay_images' is not defined"
     ]
    }
   ],
   "source": [
    "# images = [img for img in replay_images]\n",
    "# mediapy.show_video(replay_images, fps=5)\n",
    "mediapy.show_video(replay_images, fps=10, codec='gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] using task orders [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "[Warning]: assets path /home/ahrilab/Desktop/LIBERO/libero/libero/./assets does not exist!\n",
      "[Warning]: bddl_files path /home/ahrilab/Desktop/LIBERO/libero/libero/./bddl_files does not exist!\n",
      "[Warning]: init_states path /home/ahrilab/Desktop/LIBERO/libero/libero/./init_files does not exist!\n",
      "[info] retrieving task 1 from suite libero_spatial, the language instruction is pick up the black bowl next to the ramekin and place it on the plate, and the bddl file is /home/ahrilab/Desktop/LIBERO/libero/libero/./bddl_files/libero_spatial/pick_up_the_black_bowl_next_to_the_ramekin_and_place_it_on_the_plate.bddl\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "[error] /home/ahrilab/Desktop/LIBERO/libero/libero/./bddl_files/libero_spatial/pick_up_the_black_bowl_next_to_the_ramekin_and_place_it_on_the_plate.bddl does not exist!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m task_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      4\u001b[0m resize \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m512\u001b[39m\n\u001b[0;32m----> 7\u001b[0m replay_images \u001b[38;5;241m=\u001b[39m \u001b[43mlibero_frames\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask_suite_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m mediapy\u001b[38;5;241m.\u001b[39mshow_video(replay_images, fps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, codec\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgif\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[21], line 20\u001b[0m, in \u001b[0;36mlibero_frames\u001b[0;34m(task_suite_name, task_id, resize)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# step over the environment\u001b[39;00m\n\u001b[1;32m     15\u001b[0m env_args \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbddl_file_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: task_bddl_file,\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcamera_heights\u001b[39m\u001b[38;5;124m\"\u001b[39m: resize,\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcamera_widths\u001b[39m\u001b[38;5;124m\"\u001b[39m: resize\n\u001b[1;32m     19\u001b[0m }\n\u001b[0;32m---> 20\u001b[0m env \u001b[38;5;241m=\u001b[39m \u001b[43mOffScreenRenderEnv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43menv_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m env\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     22\u001b[0m env\u001b[38;5;241m.\u001b[39mreset()\n",
      "File \u001b[0;32m~/Desktop/LIBERO/libero/libero/envs/env_wrapper.py:161\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/Desktop/LIBERO/libero/libero/envs/env_wrapper.py:43\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, bddl_file_name, robots, controller, gripper_types, initialization_noise, use_camera_obs, has_renderer, has_offscreen_renderer, render_camera, render_collision_mesh, render_visual_mesh, render_gpu_device_id, control_freq, horizon, ignore_done, hard_reset, camera_names, camera_heights, camera_widths, camera_depths, camera_segmentations, renderer, renderer_config, **kwargs)\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: [error] /home/ahrilab/Desktop/LIBERO/libero/libero/./bddl_files/libero_spatial/pick_up_the_black_bowl_next_to_the_ramekin_and_place_it_on_the_plate.bddl does not exist!"
     ]
    }
   ],
   "source": [
    "# [\"libero_spatial\", \"libero_object\", \"libero_goal\", \"libero_10\"]\n",
    "task_suite_name = \"libero_spatial\" # can also choose libero_spatial, libero_object, etc.\n",
    "task_id = 1\n",
    "resize = 512\n",
    "\n",
    "\n",
    "replay_images = libero_frames(task_suite_name, task_id, resize)\n",
    "\n",
    "mediapy.show_video(replay_images, fps=10, codec='gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lerobot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
